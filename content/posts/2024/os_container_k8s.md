+++
title = '操作系统、容器和Kubernetes'
date = 2024-03-20T15:00:00+08:00
tags = ["container"]
+++

> 这篇文章是我在[工作室 wiki 上的文章](https://west2-online.feishu.cn/wiki/NR0Iwp6mtij1oRkNKNXceeTknQL)转载，原文章是富文本，比目前阅读来说会更加突出重点一些
>
> 需要注意的是，这篇文章是新人向的，里面可能有一些类似老师的语气，如有不适请谅解


这篇文章将会尽可能的从最简单的角度快速入门 k8s，即使你可能完全没接触过 k8s。

题外话：我觉得如果只是服务端研发的话，其实不那么需要懂 k8s吧，脚本什么的运维应该都会给好了？


![Rancher 的集群仪表盘](https://img.w2fzu.com/etc/202410181500819.png)

## Kubernetes和Linux发行版

很多人一开始看见 k8s 是一个容器操作系统（不知道为什么很多地方都这么写），就以为和 Ubuntu、Arch 等是一个意思。

Kubernetes可以在多种操作系统上运行。Ubuntu和CentOS都是流行的Linux发行版，它们为运行Kubernetes集群提供了基础。这些操作系统通常作为宿主机操作系统，运行Kubernetes的各个组件，包括Master节点和Worker节点上的组件。

一般来说，我们需要安装好宿主机操作系统，然后进而安装 k8s。这么看的话 k8s 更像是个常规意义上的软件，但是又不那么常规。

k8s 实际上是抽象了底层的硬件系统，比如，我们要在一台服务器上部署我们的项目，可能需要了解一个服务器，会关心 CPU 核心数、频率、GPU 数量、内存限制等等

在 k8s 中，由于通常是集群管理，一个集群中有多台服务器，我们不可能对每台服务器还剩多少 cpu 核心空闲、还剩多少内存空闲了如指掌吧？k8s 的作用就是做了一个抽象，我们只需要在一个统一的平台上发布我们的部署作业。例如 Deployment，在每个 Deployment 中我们都会设定好所需的 CPU 毫核心数（mCPU）、内存限制等，然后 k8s 会自动找到符合我们需求的服务器，然后把这个作业发布出去（找不到的话就 pending，一直到找到了）。

这就是 k8s 的一个特征：资源抽象和管理，提升一个维度，使我们不必关心更低一层的情况，k8s 帮助我们关心了。

k8s 还有其他的特征，例如
1. 容器生命周期管理：管理容器启停、更新等，类似于操作系统管理进程
2. 隔离和安全：k8s 为 Pod（后面会说）提供了一个隔离的环境，类似于操作系统的进程隔离
3. 容器调度：协调容器到节点上，在这里，容器可以视作一个轻量级进程，而 k8s 就做类似操作系统要做的CPU进程调度

所以说 k8s 是一个容器操作系统，我觉得没问题

## 集群、节点与 Pod

集群、节点与 Pod构成了 Kubernetes 的基本工作原理

### Cluster

Kubernetes集群是一组机器的集合，这些机器一起工作，提供一个统一的视图，使得它们看起来像是一个单一的实体。集群是Kubernetes的最高级别的部署单元，它允许容器化应用跨多个计算资源运行。集群管理着所有的资源，确保应用程序的运行和管理。

简单来说，在抽象后，集群可以视作一台服务器，只不过具体的实现是由多台服务器构成

### Node

节点是集群中的一个工作机器，可以是物理机或虚拟机。每个节点都被Master节点管理，它负责运行Pod，并提供它们所需的环境。在Kubernetes中，有两种类型的节点：
- Master节点：运行控制平面组件，如API服务器、调度器、控制器管理器等，负责管理集群的状态，进行调度决策，处理用户请求，以及执行其他管理任务。
- 工作节点（Worker Node）：运行实际的应用程序容器，每个工作节点都运行Kubelet和Kube-Proxy等进程，这些进程管理Pod和节点的网络通信。

继续从集群出发，Node 可以理解为集群中的一台服务器。不同的 Node 也有等级之分，比如 Master 节点和 Worker 节点，节点的集合构成了集群，集群又服务于 k8s。

### Pod

这部分应该是最难理解的了。Pod是Kubernetes中最小的部署单元，它是一组一个或多个容器构成的，这些容器共享存储、网络和运行配置（我觉得这里可以理解成 Pod 是一个更高级的 Docker compose）。每个Pod都被分配一个唯一的IP地址。Pod可以在节点之间移动，但它们的生命周期是有限的，当Pod停止运行或被删除时，它不会被重新创建。Kubernetes中的应用程序通常部署在Pod中，而不是直接部署在容器中。

一个Pod不能分布在多个Node中。在Kubernetes中，Pod是最小的部署单元，它是一个封装环境，用于运行一个或多个紧密相关的容器。Pod内的所有容器都共享相同的网络命名空间（包括IP地址和端口空间）、存储和操作系统级别的上下文。这意味着Pod中的容器必须全部位于同一个物理机或虚拟机上，即同一个Node上。

请注意里面的最小部署单元这个意思。这意味着 Pod 可能是多个容器的集合，但并不意味着容器之间是完全互通的，它们还是容器，这一点不会变。

## 硬件

这里以 CPU 和内存为例子，在 k8s 中，有一个毫核心数（mCPU）的概念，1000mCPU = 1CPU 核心，这将 CPU 的颗粒度细化了。

 k8s 中，会要求你为 Pod 指定资源的请求（request）和限制（limit），其内置的调度器（scheduler）会在节点中寻找满足条件的节点。

如果没有节点满足条件，这个Pod 将会保持 Pending（等待），一直到有节点满足条件，才会进入编排（compose）。

Kubernetes 通过 cgroup（Linux 控制组）来实现对 CPU 和内存资源的抽象和隔离。cgroup 允许 Kubernetes 对容器的资源使用进行颗粒度控制，包括：
- 限制：确保容器不会消耗超过其分配的资源。（limit）
- 保证：确保容器至少会获得其请求的资源量。（request）
- 隔离：确保一个容器的资源使用不会影响到其他容器。

![rancher 上的硬件资源配置](https://img.w2fzu.com/etc/202410181501186.png)

## 存储

下图是一个 Pod 的存储管理，我们可以注意到里面有超级多的存储类型，从云端存储到本地存储，还有 NFS、VMWare vSphere 等等。

在 k8s 中，我们不需要关心具体存储是怎样的，它可以是任何类型（只要它能存），我们所需的就是在管理员界面添加这个存储支持，对于普通人员来说，我们只需要简单的在 web 界面声明这个存储，然后引用就行了。

![Rancher 上Pod 的存储管理](https://img.w2fzu.com/etc/202410181502570.png)

引用也很简单，我们直接把持久卷挂载到容器内（例如/app/config指的是你容器内的地址，请再注意分辨一下集群、节点、Pod 和容器本身）

对于一个持久卷，可以挂载到同一个 Pod 下的多个服务内，同时同一个持久卷可以挂载到同一个容器的不同挂载点（例如图里的 log-volume 可以挂载到/app/data/log，也可以继续添加挂载点）

这个实际上第一次遇见是很难理解的，存储被抽象成了一个高维的概念，它不局限于你是 最普通的一块硬盘、云存储还是 NFS，你不需要关心它的实现，你只需要知道它能存东西（这句话前面也说了），同时你可以以非常简单的方式，像linux 中挂载磁盘的命令一样使用它（mount [选项] <设备名> <挂载点>），这甚至是可视化的

举个例子，Nacos、etcd 也可以视为一个存储。可以了解一下 k8s 中 ConfigMap 的概念，正如其名，这存储的就是应用的配置，里面形式通常就是键值对（key-value）。

更直观一点，假如你有一个配置文件 config.yaml，文件内容是ozline，那么在 ConfigMap 中，就是一个 key 为config.yaml，value 为ozline的键值对（value 可以很大）

ConfigMap 和 PVC（PersistentVolumeClaim）都可以被当做硬盘来挂载到容器的目录下，但是前者并非是持久化储存，即使 Pod 重启时它也不会变，但容器内的应用程序无法修改 ConfigMap 的内容，必须由管理员来在后台修改它，配置才会变更，而后者可以被容器内的应用程序修改内容（比如新建一个文件）

![](https://img.w2fzu.com/etc/202410181503744.png)

![Rancher 平台下创建一个 ConfigMap 的图示](https://img.w2fzu.com/etc/202410181503500.png)

## 网络

第一次上手 Docker 时估计都会被那该死的网络给折腾，被折腾的说明计算机网络这门课没学好，这里直接讲四个场景：Pod 间通信、Pod 内通信、Service 和 Ingress

### Pod 内通信

在前面有说过，Pod 更像是个高级的 docker compose，Pod 内通信的方式也一定程度上佐证了这一点
在同一个 Pod内的容器共享相同的网络命名空间，意味着可以通过localhost进行通信，使用相同的网络接口和端口

举个例子，假设现在一个 Pod 内有两个容器，分别叫server 和 web（注意，name 是很重要的）。这很好理解，server 是服务端程序，web 是前端程序。我们假设 web 容器开放了 80 端口，同时访问这个容器的 80 端口可以返回前端页面数据

一个简单的例子，你进入 server，调用一个 curl 指令（`curl http://web/`）此时如果 web 容器开放了 80 端口，那么 curl 将会返回容器的前端页面数据。

### Pod 间通信

> Kubernetes 要求集群中的所有 Pod 都在一个共享的、扁平的网络空间中，这意味着每个 Pod 都能够直接与其他所有 Pod 通信，而无需网络地址转换 (NAT)。这通常是通过 CNI（容器网络接口）插件来实现的，如 Calico、Flannel、Weave 等。

很晦涩难懂，简单来说，Pod 被分配了唯一 IP 地址，在集群内这些 IP 地址都是打通的，就像前面所说，Pod 内共享端口，这意味着两个不同的容器不能监听一样的端口。假设 Pod 被分配的 IP 是`10.0.0.1`，那么你直接访问`10.0.0.1:80`就可以访问到前端页面资源了

### Service

Pod 指的是一个最小可部署单元，这个单元内可能包含了一套完整的系统（比如前端、后端、鉴权中台等，但是这是不好的，应该还是要做拆分），考虑到可用性，我们应该不太可能只会让这套系统部署一个吧，万一哪天哪个挂了不就服务不可用了。这就引出了 Service概念

Service 是对一组执行相同功能的 Pod 的抽象，它提供一个固定的 IP 地址和 DNS 名称，Pod 可以通过这个地址与服务后端的任意 Pod 通信。
Service 类型：
- ClusterIP（默认）：服务只能在集群内部访问。
- NodePort：服务可通过每个节点的特定端口从集群外部访问。
- LoadBalancer：服务可以通过云提供商的负载均衡器从外部访问。
- ExternalName：服务通过返回一个外部 DNS 名称而不是常规的 ClusterIP。

很难理解，但是我觉得可以类比 Service 为一个LoadBalancer（负载均衡器）。也就是说，Service 提供了一个统一的访问入口（固定 IP 和 DNS 名称），Service 背后可能有 一个或多个功能完全一样的 Pod。这也是一层抽象封装，让用户不需要关心有哪几个具体的 IP，哪几个 Pod 不可用，直接访问 Service 提供的统一访问入口，Service 负责帮你解决掉剩下的部分。

需要注意的是：Service 通常在第四层（传输层）进行负载均衡，尽管也有支持第七层负载均衡的 Service 类型，如 `LoadBalancer` 类型的 Service 可以使用云提供商的负载均衡器。

### Ingress

> Ingress 是一个 API 对象，它管理外部用户对在 Kubernetes 集群内部运行的服务的访问。Ingress 可以提供负载均衡、SSL 终端和基于名称的虚拟托管。

Ingress 的作用一列出来，你就发现这简直就是个网关：
- 基于主机名/路径的路由：可以基于请求域名（www.abc.com）或请求路径（/api/v1）来将请求转发到不同的 Service（不是 Pod）
- 负载均衡：Ingress 在应用层（OSI 模型，第七层）进行负载均衡，主要处理 HTTP/HTTPS 流量
- TLS 终端解密：我们可以在 Ingress 中配置 TLS证书，为网站提供 HTTPS 支持
- 自定义规则：可以使用注解（Annotations）来定义 Ingress 的行为，如设置超时、限制连接数等

不过简单来说，Ingress 在 Service 的前面，一个 HTTP请求抵达 k8s 时，会先经过 Ingress，再经过 Service，最后抵达可用的 Pod。Ingress 负责把手 k8s 的大门，经过Ingress 后的所有流量，都在 k8s 内部运作了。

### Service 和 Ingress 为什么都有负载均衡

> 在实际使用中，两者往往结合使用：Ingress 处理入口流量并根据规则将流量路由到不同的 Service，每个 Service 再将流量分发到其管理的 Pod。这样的结构提供了灵活性、可扩展性和高可用性。

也就是说，会LB 两次。说到底感觉就是什么解耦、高可用、可拓展 balabala 的.....

### 底层细节

实现这些网络特性通常依赖于底层的网络提供商和插件。例如，CNI 插件负责在 Pod 启动时配置网络接口，设置路由规则，以及可能的跨节点通信。Service 通常由 kube-proxy 组件实现，它负责在节点上设置 iptables 规则或使用 IPVS 来实现服务发现和负载均衡。Ingress 控制器则是一个单独的应用程序，通常作为 Pod 运行在集群中，负责处理进入集群的外部 HTTP/HTTPS 流量。

## Kubernetes 是一个巨大的 YAML 文件解析系统

如果你真实的使用过 rancher，你可以发现它虽然提供了图形化界面，但不如直接编辑它们的yaml 来的好用（主观）。
比如我们打算发布一个 Deployment，我们其实可以直接写个 yaml，然后让 k8s 解析，如下图所示

## 容器视角下的前后端项目部署

解决了前面的概念理解，接下来可以实现一个部署了。在我的一个项目中，我的启动脚本一部分如下

```bash
start_container() {
    local service_name="$1"

    if [[ ! " ${SERVICES[*]} " =~ " ${service_name} " ]]; then
        echo "Error：Service $service_name not in list。Available：${SERVICES[*]}"
        exit 1
    fi

    echo "start container $service_name"
    docker run -d --name "west2online-$service_name" \
    -e service="$service_name" \
    --net=host \
    -v "$DIR/config:/app/config" \
    -v "$DIR/data/resource:/app/data/resource" \
    -v "$DIR/data/log:/app/data/log" \
    "$IMAGE_NAME"
}
```

对于一个已经封装好的容器，我们可以把它视为一个黑盒，我们不需要关心它内部是怎么运行的，我们只需要
1. 指定好网络类型和端口映射（网络）
2. 指定好容器映射（存储）
3. 指定好环境变量（对于一些容器镜像，其内部可能有多个服务，我们可以通过指定环境变量来让容器启动不同的服务；除此之外，环境变量也可能影响服务器的运行效果）
然后直接 docker run 就完事了

### 打包镜像

后端打包镜像太简单了，这里略过。

前端也很简单，但是问题在于容器这个东西偏后端，前端不一定会，门槛就上来了。

实际上，前端需要的也只是一个包含 Nginx 的 Docker 基础镜像，然后
1. 编写一份容器内的 Nginx 流量规则（Nginx 也是一个网关）
2. COPY 前端编译好的项目到容器的某个位置
3. Docker build

![](https://img.w2fzu.com/etc/202410181512910.png)

### 上集群（以 Rancher 为例）

这里直接截图了，太简单。前端的话也是类似，填写好镜像、名词、暴露一下网络端口，设置一下环境变量（如果有）然后就结束了。

后端比前端还需要做的一件事就是做一个存储的映射

![](https://img.w2fzu.com/etc/202410181512592.png)

除了这些外，其实要编辑一下资源使用

![](https://img.w2fzu.com/etc/202410181512719.png)

然后保存，等 K8s 编排就行了

![](https://img.w2fzu.com/etc/202410181512717.png)

## 其他

其实 k8s 的概念有很多，比如一个工作负载就还有 Deployment（给常见的服务端程序用）、StatefulSet（通常给数据库用）、DaemonSet（给日志搜集、监控代理用）。
但是主要还是前面需要理解一下（懒得写了），感觉全都是抽象抽象抽象抽象

题外话，daemon 这个单词大家都会吗？是不是会在很多地方看见这个单词？
